n = 10; N = 1000;
p = log(N)/n
p*(1-p)*n <= log(N)
p = log(N)/N
p = 2*log(N)/N
dist = rbinom(n = n, size = N, prob = p)
dist = rbinom(n = N, size = n, prob = p)
max(dist)
log(N)
count(dist > 0)
sum(dist > 0)
dist > 0
sum(dist > 0)/N
p*N/n
p*N*n
.libPaths()
.libPaths('C:/Users/bpames/R')
.libPaths()
.libPaths()
.libPaths('C:/Users/bpames/R')
.libPaths()
.libPaths()
.libPaths('C:/Users/bpames/R')
.libPaths()
.03^2
0.0009
ll = ph - 1.96*sqrt(ph*(1-ph)/200)
# P1.
ph = 0.39
ll = ph - 1.96*sqrt(ph*(1-ph)/200)
ul = ph + 1.9645*sqrt(ph*(1-ph)/200)
ll = ph - 1.9645*sqrt(ph*(1-ph)/200)
# P2.
n = (1.96/0.03)^2*0.25
#P3.
Sp <- (199*5.1^2 + 149*6.3^2)/(199+149)
#P3.
Vp <- (199*5.1^2 + 149*6.3^2)/(199+149)
l3 <- (50.7-42.3) - 2.33*sqrt(Vp)
l3 <- (50.7-42.3) - 2.33*sqrt(Vp)*sqrt(1/200 + 1/150)
u3 <- (50.7-42.3) + 2.33*sqrt(Vp)*sqrt(1/200 + 1/150)
#p4.
c1 = qchisq(p=0.01, df = 9, lower.tail = TRUE)
c2 = qchisq(p=0.01, df = 9, lower.tail = FALSE)
l4 = 9*(0.29)^2/c2
u4 = 9*(0.29)^2/c1
#p4.
c1 <- qchisq(p=0.025, df = 9, lower.tail = TRUE)
c2 <- qchisq(p=0.025, df = 9, lower.tail = FALSE)
l4 <- 9*(0.29)^2/c2
u4 <- 9*(0.29)^2/c1
.libPaths()
.libPaths('C:/Users/bpames/R')
.libPaths()
# Load ggplot package.
library(ggplot2)
# Initialize data.
nsamples <- 50
N <- 1000
p <- 0.5
# Initialize hatpn.
hatpn <- matrix(0, nrow = nsamples, ncol = N)
# Plot baseline.
mid <- rep(0.5, N)
plot(mid, xlab="N", ylab="hat p", type="l", col="blue", ylim=c(0,1), lwd=2)
i <-11
# Run Bernoulli trials (binomial of size 1)
X <-  rbinom(n=N, size=1, prob=p)
# Get sample proportion over first n trials for n=1, 2, ..., N/
hatpn[i, 1:N] <- sapply(1:N, function(x){sum(X[1:x])/x})
# Plot values of estimator.
lines(hatpn[i,1:N], col="red", lwd=2)
# Plot baseline.
mid <- rep(0.5, N)
plot(mid, xlab="N", ylab="hat p", type="l", col="blue", ylim=c(0,1), lwd=2)
for (i in 1:nsamples)
{
# Run Bernoulli trials (binomial of size 1)
X <-  rbinom(n=N, size=1, prob=p)
# Get sample proportion over first n trials for n=1, 2, ..., N/
hatpn[i, 1:N] <- sapply(1:N, function(x){sum(X[1:x])/x})
# Plot values of estimator.
lines(hatpn[i,1:N], col="red", lwd=2)
}
# Plot baseline again.
lines(mid, col="blue", lwd=3)
#+++++++++++++++++++++++++++++++
# Plot histograms.
#+++++++++++++++++++++++++++++++
# n=10.
df <- data.frame(p = hatpn[1:nsamples, 10])
ggplot(df, aes(p)) + geom_histogram(alpha = 0.5, aes(y = ..density..), binwidth=0.1, fill="darkred", col="darkred", position = 'identity')+ xlim(0,1) + labs(title="Histogram of hat p values (n=10)")
# n=250.
df250 <- data.frame(p = hatpn[1:nsamples, 250])
ggplot(df250, aes(p)) + geom_histogram(alpha = 0.5, aes(y = ..density..), binwidth=0.01, fill="darkorchid4", col="darkorchid4", position = 'identity')+ xlim(0,1) + labs(title="Histogram of hat p values (n=250)")
# n=500.
df500 <- data.frame(p = hatpn[1:nsamples, 500])
ggplot(df500, aes(p)) + geom_histogram(alpha = 0.5, aes(y = ..density..), binwidth=0.01, fill="dodgerblue4", col="dodgerblue4", position = 'identity')+ xlim(0,1) + labs(title="Histogram of hat p values (n=500)")
# n=1000.
df1000 <- data.frame(p = hatpn[1:nsamples, 1000])
ggplot(df1000, aes(p)) + geom_histogram(alpha = 0.5, aes(y = ..density..), binwidth=0.01, fill="seagreen4", col="seagreen4", position = 'identity')+ xlim(0,1) + labs(title="Histogram of hat p values (n=1000)")
# Load ggplot package.
library(ggplot2)
# Initialize data.
nsamples <- 50
N <- 1000
p <- 0.5
# Initialize hatpn.
hatpn <- matrix(0, nrow = nsamples, ncol = N)
# Plot baseline.
mid <- rep(0.5, N)
plot(mid, xlab="N", ylab="hat p", type="l", col="blue", ylim=c(0,1), lwd=2)
i <-1
# Run Bernoulli trials (binomial of size 1)
X <-  rbinom(n=N, size=1, prob=p)
# Get sample proportion over first n trials for n=1, 2, ..., N/
hatpn[i, 1:N] <- sapply(1:N, function(x){sum(X[1:x])/x})
# Plot values of estimator.
lines(hatpn[i,1:N], col="red", lwd=2)
plot(mid, xlab="N", ylab="hat p", type="l", col="blue", ylim=c(0,1), lwd=2)
for (i in 1:nsamples)
{
# Run Bernoulli trials (binomial of size 1)
X <-  rbinom(n=N, size=1, prob=p)
# Get sample proportion over first n trials for n=1, 2, ..., N/
hatpn[i, 1:N] <- sapply(1:N, function(x){sum(X[1:x])/x})
# Plot values of estimator.
lines(hatpn[i,1:N], col="red", lwd=2)
}
# Plot baseline again.
lines(mid, col="blue", lwd=3)
#+++++++++++++++++++++++++++++++
# Plot histograms.
#+++++++++++++++++++++++++++++++
# n=10.
df <- data.frame(p = hatpn[1:nsamples, 10])
ggplot(df, aes(p)) + geom_histogram(alpha = 0.5, aes(y = ..density..), binwidth=0.1, fill="darkred", col="darkred", position = 'identity')+ xlim(0,1) + labs(title="Histogram of hat p values (n=10)")
# n=250.
df250 <- data.frame(p = hatpn[1:nsamples, 250])
ggplot(df250, aes(p)) + geom_histogram(alpha = 0.5, aes(y = ..density..), binwidth=0.01, fill="darkorchid4", col="darkorchid4", position = 'identity')+ xlim(0,1) + labs(title="Histogram of hat p values (n=250)")
# n=500.
df500 <- data.frame(p = hatpn[1:nsamples, 500])
ggplot(df500, aes(p)) + geom_histogram(alpha = 0.5, aes(y = ..density..), binwidth=0.01, fill="dodgerblue4", col="dodgerblue4", position = 'identity')+ xlim(0,1) + labs(title="Histogram of hat p values (n=500)")
# n=1000.
df1000 <- data.frame(p = hatpn[1:nsamples, 1000])
ggplot(df1000, aes(p)) + geom_histogram(alpha = 0.5, aes(y = ..density..), binwidth=0.01, fill="seagreen4", col="seagreen4", position = 'identity')+ xlim(0,1) + labs(title="Histogram of hat p values (n=1000)")
.libPaths()
.libPaths('C:/Users/bpames/R')
.libPaths()
install.packages(c("assertthat", "backports", "BH", "broom", "callr", "caret", "cli", "clipr", "colorspace", "curl", "data.table", "ddalpha", "devtools", "dplyr", "e1071", "FNN", "fs", "geometry", "ggplot2", "ggthemes", "git2r", "glue", "gower", "gstat", "gtable", "lava", "lazyeval", "maptools", "openssl", "pillar", "pkgbuild", "pls", "processx", "ps", "psych", "purrr", "R6", "Rcpp", "recipes", "remotes", "rlang", "robustbase", "RSpectra", "rstudioapi", "slam", "SnowballC", "stringi", "stringr", "tibble", "tidyr", "tm", "usethis", "zoo"))
source('C:/Users/bpames/github/FZVD/R/penzda.R')
setwd("C:/Users/bpames/github/FZVD/R")
.libPaths()
.libPaths('C:/Users/bpames/R')
.libPaths()
import('ECGtest.csv')
library(readr)
train <- read_csv("data/ECGtrain.csv", col_names = FALSE,
col_types = cols(X1 = col_factor(levels = c("1",
"2"))))
View(train)
library(readr)
ECGtest <- read_csv("data/ECGtest.csv", col_names = FALSE,
col_types = cols(X1 = col_factor(levels = c("1",
"2"))))
View(ECGtest)
View(ECGtest)
test = ECGtest
clear ECGtest
clear(ECGtest)
rm(ECGtest)
save.image("C:/Users/bpames/github/FZVD/R/data/ECG.RData")
train$X1
as.matrix(train)
# Make ASDA Input.
Xt = train[:, 2:137]
# Make ASDA Input.
Xt = train[, 2:137]
Xtest <- test[, 2:137]
# Make ASDA Input.
[n,p] = dim(train)
# Make ASDA Input.
(n,p) = dim(train)
# Make ASDA Input.
dim(train)
# Make ASDA Input.
n = dim(train)$1
# Make ASDA Input.
n = dim(train)[1]
p <- dim(train)[2] - 1
Xt <- train[, 2:(p+1)]
Xtest <- test[, 2:(p+1)]
ntest <- dim(test)[1]
k <- nlevels(train$X1)
Yt <- matrix(0, n, k)
for (i in 1:n){
Yt[i, train$X1[i]] <-1
}
View(Yt)
View(train)
View(Yt)
Ytest <- matrix(0, ntest, k)
for (i in 1:ntest){
Ytest[i, test$X1[i]] <-1
}
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# Call ASDA.
library(accSDA)
sdaDVs <- ASDA(Xt = Xt, Yt = Yt)
sdaDVs <- ASDA(Xt = as.matrix(Xt), Yt = Yt)
nrow(as.matrix(Xt))
nrow(Yt)
mean(Xt)
Xt <- as.matrix(Xt)
colMeans(Xt)
train <- c(1:40,51:90,101:140)
Xtrain <- iris[train,1:4]
nX <- normalize(Xtrain)
Xtrain <- nX$Xc
Ytrain <- iris[train,5]
Xtest <- iris[-train,1:4]
Xtest <- normalizetest(Xtest,nX)
Ytest <- iris[-train,5]
P <- 300 # Number of variables
N <- 50 # Number of samples per class
# Mean for classes, they are zero everywhere except the first 3 coordinates
m1 <- rep(0,P)
m1[1] <- 3
m2 <- rep(0,P)
m2[2] <- 3
m3 <- rep(0,P)
m3[3] <- 3
# Sample dummy data
Xtrain <- rbind(MASS::mvrnorm(n=N,mu = m1, Sigma = diag(P)),
MASS::mvrnorm(n=N,mu = m2, Sigma = diag(P)),
MASS::mvrnorm(n=N,mu = m3, Sigma = diag(P)))
Xtest <- rbind(MASS::mvrnorm(n=N,mu = m1, Sigma = diag(P)),
MASS::mvrnorm(n=N,mu = m2, Sigma = diag(P)),
MASS::mvrnorm(n=N,mu = m3, Sigma = diag(P)))
# Generate the labels
Ytrain <- factor(rep(1:3,each=N))
Ytest <- Ytrain
Ytrain
load("C:/Users/bpames/github/FZVD/R/data/ECG.RData")
Ytrain <- train$X1
Xtrain <- train[, 2:(p+1)]
Ytest <- test$X1
ntest <- dim(test)[1]
sdaDVs <- ASDA(Xt = Xtrain, Yt = Ytrain)
res = sdaDVs
res <- ASDA(Xt = Xtrain, Yt = Ytrain)
# Plot the projected training data, it is projected to
# 2-dimension because we have 3 classes. The number of discriminant
# vectors is maximum number of classes minus 1.
XtrainProjected <- Xtrain%*%res$beta
# Plot the projected training data, it is projected to
# 2-dimension because we have 3 classes. The number of discriminant
# vectors is maximum number of classes minus 1.
XtrainProjected <- as.matrix(Xtrain)%*%res$beta
plot(XtrainProjected[,1],col=Ytrain)
# Predict on the test data
preds <- predict(res, newdata = Xtest)
# Plot projected test data with predicted and correct labels
XtestProjected <- Xtest%*%res$beta
# Plot projected test data with predicted and correct labels
XtestProjected <- as.matrix(Xtest)%*%res$beta
Xtest <- test[, 2:(p+1)]
Ytest <- test$X1
ntest <- dim(test)[1]
# Predict on the test data
preds <- predict(res, newdata = Xtest)
# Plot projected test data with predicted and correct labels
XtestProjected <- as.matrix(Xtest)%*%res$beta
plot(XtestProjected[,1],col=Ytest,
main="Projected test data with original labels")
plot(XtestProjected[,1],col=preds$class,
main="Projected test data with predicted labels")
plot(XtestProjected[,1],col=Ytest,
main="Projected test data with original labels")
plot(XtestProjected[,1],col=preds$class,
main="Projected test data with predicted labels")
# Calculate accuracy
sum(preds$class == Ytest)/(3*N) # We have N samples per class, so total 3*N
# Calculate accuracy
sum(preds$class == Ytest)/ntest # We have N samples per class, so total 3*N
plot(res$beta)
plot(res$beta, type = 'l')
res$theta
load("C:/Users/bpames/github/FZVD/R/data/ECG.RData")
# Make ASDA Input.
n <- dim(train)[1]
p <- dim(train)[2] - 1
Ytrain <- train$X1
Xtrain <- train[, 2:(p+1)]
Xtest <- test[, 2:(p+1)]
Ytest <- test$X1
ntest <- dim(test)[1]
Xtrain <- as.matrix(train[, 2:(p+1)])
Xtest <- as.matrix(test[, 2:(p+1)])
save.image("C:/Users/bpames/github/FZVD/R/data/ECG.RData")
labels(Ytest)
labels(Ytrain)
levels(Ytrain)
Ytrain = 1
Ytrain == 1
Xtrain <- as.matrix(train[, 2:(p+1)])
Ytrain <- train$X1
Ytrain == 1
Xtrain[Ytrain==1, 3]
source('C:/Users/bpames/github/FZVD/R/penzda.R')
#++++++++++++++++++++++++++++++++++++++++++++++++++++
# Test penzda.
cmns <- penzda(Xt = Xtrain, Yt = Ytrain)
source('C:/Users/bpames/github/FZVD/R/penzda.R')
#++++++++++++++++++++++++++++++++++++++++++++++++++++
# Test penzda.
cmns <- penzda(Xt = Xtrain, Yt = Ytrain)
View(cmns)
Ytrain
labs <- levels(Yt)
labs <- levels(Ytrain)
labs
i = 2
classobs <- Xt[Yt == labs[i], ]
Xt = Xtrain
Yt = Ytrain
classobs <- Xt[Yt == labs[i], ]
colMeans(classobs)
classMeans <- matrix(0, p, k)
classMeans <- matrix(0, p, nlevels(Yt))
classMeans[,i] <- colMeans(classobs)
classMeans
1:k
k <- nlevels(labs)
1:k
1 to k
as.numeric(k)
k
nlevels(labs)
nlevels(Yt)
k <- nlevels(Yt)
1:k
#++++++++++++++++++++++++++++++++++++++++++++++++++++
# Test penzda.
cmns <- penzda(Xt = Xtrain, Yt = Ytrain)
cmns
#++++++++++++++++++++++++++++++++++++++++++++++++++++
# Test penzda.
cmns <- penzda(Xt = Xtrain, Yt = Ytrain)
#++++++++++++++++++++++++++++++++++++++++++++++++++++
# Test penzda.
cmns <- penzda(Xt = Xtrain, Yt = Ytrain)
source('C:/Users/bpames/github/FZVD/R/penzda.R')
#++++++++++++++++++++++++++++++++++++++++++++++++++++
# Test penzda.
cmns <- penzda(Xt = Xtrain, Yt = Ytrain)
i in 1:2
for (i in 1:2){print(i)}
source('C:/Users/bpames/github/FZVD/R/penzda.R')
#++++++++++++++++++++++++++++++++++++++++++++++++++++
# Test penzda.
cmns <- penzda(Xt = Xtrain, Yt = Ytrain)
cmns$cmns
source('C:/Users/bpames/github/FZVD/R/penzda.R')
#++++++++++++++++++++++++++++++++++++++++++++++++++++
# Test penzda.
cmns <- penzda(Xt = Xtrain, Yt = Ytrain)
source('C:/Users/bpames/github/FZVD/R/penzda.R')
cmns <- penzda(Xt = Xtrain, Yt = Ytrain)
#++++++++++++++++++++++++++++++++++++++++++++++++++++
# Test penzda.
library(MASS)
cmns <- penzda(Xt = Xtrain, Yt = Ytrain)
